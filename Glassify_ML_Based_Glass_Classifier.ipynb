{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhKESP0nUbbN",
        "outputId": "2eed6888-42b6-4d8d-81e1-2d6d364fe0c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before SMOTE: [ 0 70 76 17  0 13  9 29]\n",
            "After SMOTE: [ 0 76 76 76  0 76 76 76]\n",
            "\n",
            "Test Accuracy: 89.47%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.74      0.89      0.81        19\n",
            "           2       0.87      0.68      0.76        19\n",
            "           3       0.84      0.84      0.84        19\n",
            "           5       0.95      1.00      0.97        19\n",
            "           6       1.00      1.00      1.00        19\n",
            "           7       1.00      0.95      0.97        19\n",
            "\n",
            "    accuracy                           0.89       114\n",
            "   macro avg       0.90      0.89      0.89       114\n",
            "weighted avg       0.90      0.89      0.89       114\n",
            "\n",
            "Confusion Matrix:\n",
            " [[17  1  1  0  0  0]\n",
            " [ 3 13  2  1  0  0]\n",
            " [ 3  0 16  0  0  0]\n",
            " [ 0  0  0 19  0  0]\n",
            " [ 0  0  0  0 19  0]\n",
            " [ 0  1  0  0  0 18]]\n",
            "Cross-validated Training Accuracy: 88.32% (+/- 2.87%)\n",
            "Quick Accuracy Check:\n",
            "Training Accuracy: 0.9854\n",
            "Testing Accuracy: 0.8947\n",
            "Model and scaler saved successfully! ✅\n"
          ]
        }
      ],
      "source": [
        "# 1. Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "\n",
        "# 2. Load Data\n",
        "df = pd.read_csv('/content/glass.csv')\n",
        "\n",
        "X = df.drop('Type', axis=1)\n",
        "y = df['Type']\n",
        "\n",
        "print(f\"Before SMOTE: {np.bincount(y)}\")\n",
        "\n",
        "# 3. Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "print(f\"After SMOTE: {np.bincount(y_resampled)}\")\n",
        "\n",
        "# 4. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.25, random_state=42, stratify=y_resampled\n",
        ")\n",
        "\n",
        "# 5. Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 6. Final Optimized Gradient Boosting Classifier\n",
        "best_gbm = GradientBoostingClassifier(\n",
        "    learning_rate=0.05,\n",
        "    n_estimators=300,\n",
        "    max_depth=3,\n",
        "    max_features='sqrt',\n",
        "    subsample=0.8,\n",
        "    min_samples_split=4,\n",
        "    min_samples_leaf=2,\n",
        "    validation_fraction=0.1,\n",
        "    n_iter_no_change=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 7. Train with early stopping\n",
        "best_gbm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 8. Evaluate on test set\n",
        "y_pred = best_gbm.predict(X_test_scaled)\n",
        "\n",
        "print(f\"\\nTest Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%\\n\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# 9. Cross-validated training accuracy\n",
        "cv_scores = cross_val_score(best_gbm, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validated Training Accuracy: {cv_scores.mean()*100:.2f}% (+/- {cv_scores.std()*100:.2f}%)\")\n",
        "\n",
        "print(\"Quick Accuracy Check:\")\n",
        "print(f\"Training Accuracy: {best_gbm.score(X_train_scaled, y_train):.4f}\")\n",
        "print(f\"Testing Accuracy: {best_gbm.score(X_test_scaled, y_test):.4f}\")\n",
        "\n",
        "# 10. Save model and scaler\n",
        "joblib.dump(best_gbm, 'gradient_boosting_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "print(\"Model and scaler saved successfully! ✅\")\n"
      ]
    }
  ]
}